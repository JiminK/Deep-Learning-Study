# [ LAB 03 - Deeper Look at Gradient Descent ]
---

"SGD가 어떻게 loss를 최소화 시키는 것인지."

- Hypothesis (Linear Regression)    
> H(x) = Wx + b ⇒ H(x) = Wx **(no bias)**

위와 같이 bias를 없애고 실습할 것임.

- 어떻게 모델의 좋고 나쁨을 평가해?    
⇒ **cost function** 정의    
cost function : 모델의 예측값이 실제 데이터와 얼마나 다른지 나타내는 함수    
**잘 학습됐을수록 cost 작다.** 

